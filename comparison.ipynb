{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intelligent-queensland",
   "metadata": {},
   "source": [
    "# Comparing the predictions from multiple models\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cardiac-representation",
   "metadata": {},
   "source": [
    "I've trained three networks so far, all for 60 epochs, batch size 128:\n",
    "- a simple network consisting of one `LSTM` layer with 128 units\n",
    "- a simple network comprising one `LSTM` layer with 64 units\n",
    "- a deeper network containing:\n",
    "    - 128-unit `LSTM` + 0.8 `Dropout`\n",
    "    - 64-unit `LSTM` + 0.8 `Dropout`\n",
    "    - 32-unit `LSTM` + 0.8 `Dropout`\n",
    "    \n",
    "I want to generate sequences from all three of them and see how they compare, from maybe 3 seed sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "stunning-joseph",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "careful-france",
   "metadata": {},
   "source": [
    "Prepare the text and load the saved models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "phantom-association",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"infinite_jest_text.txt\"\n",
    "\n",
    "with open(path, \"r\") as f:\n",
    "    text = f.read()\n",
    "    \n",
    "text = text.lower().replace(\"\\n\", \" \")\n",
    "chars = sorted(list(set(text)))\n",
    "\n",
    "# We need to be able to convert from chars to indices and vice-versa.\n",
    "char_to_idx = dict((c, i) for (i, c) in enumerate(chars))\n",
    "idx_to_char = dict((i, c) for (i, c) in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "arranged-kenya",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'64unit_60epochs': <tensorflow.python.keras.engine.sequential.Sequential object at 0x7fa2e03277f0>, '128unit_60epochs': <tensorflow.python.keras.engine.sequential.Sequential object at 0x7fa2d3f4db80>, 'deep_60epochs': <tensorflow.python.keras.engine.sequential.Sequential object at 0x7fa3118d83a0>}\n"
     ]
    }
   ],
   "source": [
    "# Saved models are detailed above.\n",
    "model_names = [\"64unit_60epochs\", \"128unit_60epochs\", \"deep_60epochs\"]\n",
    "models = {}\n",
    "\n",
    "for model_name in model_names:\n",
    "    models[model_name] = load_model(\"saved_models/\" + model_name)\n",
    "\n",
    "print(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "connected-rogers",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    \"\"\"Sample from an array of predictions with a given temperature/diversity.\n",
    "       Author: fchollet\n",
    "    \"\"\"\n",
    "    preds = np.asarray(preds).astype(\"float64\")\n",
    "    preds = np.log(preds) / temperature\n",
    "    preds = np.exp(preds)\n",
    "    preds /= np.sum(preds)\n",
    "    return np.argmax(np.random.multinomial(1, preds, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "blind-german",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-507ff383eb62>:6: RuntimeWarning: divide by zero encountered in log\n",
      "  preds = np.log(preds) / temperature\n"
     ]
    }
   ],
   "source": [
    "temperatures = [0.3, 0.7, 1.0]\n",
    "sentlen = 40\n",
    "seed_index = np.random.randint(len(text)-sentlen)\n",
    "seed_sentence = text[seed_index : seed_index + sentlen]\n",
    "out_path = \"output.txt\"\n",
    "\n",
    "with open(out_path, \"a\") as out:\n",
    "    out.write(\"Seed sentence: {}\\n\\n\".format(seed_sentence))\n",
    "    for name, model in models.items():\n",
    "        out.write(\"#\"*40 + \"\\n\")\n",
    "        out.write(\"Model: {}\\n\".format(name))\n",
    "        for temperature in temperatures:\n",
    "            out.write(\"_\"*40 + \"\\n\")\n",
    "            out.write(\"Temp: {}\\n\".format(temperature))\n",
    "\n",
    "            generated = \"\"\n",
    "            for i in range(400):\n",
    "                # Encode seed sentence.\n",
    "                x_pred = np.zeros((1, sentlen, len(chars)))\n",
    "                for char_index, char in enumerate(seed_sentence):\n",
    "                    x_pred[0, char_index, char_to_idx[char]] = 1\n",
    "\n",
    "                preds = model.predict(x_pred)[0]\n",
    "                next_char = idx_to_char[sample(preds, temperature)]\n",
    "\n",
    "                seed_sentence = seed_sentence[1:] + next_char\n",
    "                generated += next_char\n",
    "            out.write(generated + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surprised-novelty",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
